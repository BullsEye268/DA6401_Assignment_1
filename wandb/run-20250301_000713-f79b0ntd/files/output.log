_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NesterovOptimizer self.learning_rate = 0.0001 self.momentum = 0.9
Epoch  1/10, Iteration   0/844 --> Train Loss: 2.33325, Val Loss: 2.31939
Epoch  2/10, Iteration 156/844 --> Train Loss: 2.16295, Val Loss: 2.15172
Epoch  3/10, Iteration 312/844 --> Train Loss: 1.83055, Val Loss: 1.79125
Epoch  4/10, Iteration 468/844 --> Train Loss: 1.47093, Val Loss: 1.30746
Epoch  5/10, Iteration 624/844 --> Train Loss: 1.02535, Val Loss: 1.01859
Epoch  6/10, Iteration 780/844 --> Train Loss: 0.94478, Val Loss: 0.88548
Epoch  8/10, Iteration  92/844 --> Train Loss: 0.70718, Val Loss: 0.80860
Epoch  9/10, Iteration 248/844 --> Train Loss: 0.80406, Val Loss: 0.76359
Epoch 10/10, Iteration 404/844 --> Train Loss: 0.52300, Val Loss: 0.72590
Test Accuracy: 0.7363
