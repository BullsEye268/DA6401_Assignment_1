_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running AdamOptimizer self.learning_rate = 0.001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 19.89643, Val Loss: 18.90772
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.45198, Val Loss: 0.74203
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.70821, Val Loss: 0.61570
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.37824, Val Loss: 0.53553
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.58044, Val Loss: 0.49466
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.16405, Val Loss: 0.49379
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.40522, Val Loss: 0.46753
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.43879, Val Loss: 0.46227
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.67062, Val Loss: 0.41893
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.67705, Val Loss: 0.47491
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.43536, Val Loss: 0.41795
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.57802, Val Loss: 0.41290
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.39570, Val Loss: 0.38237
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.48356, Val Loss: 0.37949
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.30032, Val Loss: 0.41138
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.06794, Val Loss: 0.37440
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.40944, Val Loss: 0.38895
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.12737, Val Loss: 0.36066
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.65864, Val Loss: 0.36221
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.22516, Val Loss: 0.37872
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.39971, Val Loss: 0.35397
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.39256, Val Loss: 0.35901
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.31927, Val Loss: 0.34364
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.19323, Val Loss: 0.35020
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.20182, Val Loss: 0.38367
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.47940, Val Loss: 0.34266
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.41423, Val Loss: 0.36266
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.55416, Val Loss: 0.35032
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.35586, Val Loss: 0.36949
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.02234, Val Loss: 0.35519
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.18891, Val Loss: 0.33897
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.40508, Val Loss: 0.35076
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.22065, Val Loss: 0.35192
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.34107, Val Loss: 0.34204
Test Accuracy: 0.8714
