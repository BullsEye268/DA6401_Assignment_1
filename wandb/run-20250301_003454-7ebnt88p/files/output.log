_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 2.34039, Val Loss: 2.33207
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 1.02019, Val Loss: 0.69788
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.77525, Val Loss: 0.56762
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.45868, Val Loss: 0.51156
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.60583, Val Loss: 0.48444
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.23652, Val Loss: 0.46428
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.40115, Val Loss: 0.44661
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.25676, Val Loss: 0.43243
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.29743, Val Loss: 0.42208
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.71039, Val Loss: 0.41912
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.29204, Val Loss: 0.40752
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.27076, Val Loss: 0.40960
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.35547, Val Loss: 0.39022
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.13795, Val Loss: 0.39863
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.48452, Val Loss: 0.40701
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.33875, Val Loss: 0.37796
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.31391, Val Loss: 0.37318
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.21604, Val Loss: 0.38794
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.55562, Val Loss: 0.36735
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.13383, Val Loss: 0.37795
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.53248, Val Loss: 0.36166
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.28663, Val Loss: 0.36748
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.27488, Val Loss: 0.36652
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.48398, Val Loss: 0.36322
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.24064, Val Loss: 0.35172
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.30733, Val Loss: 0.36515
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.43004, Val Loss: 0.35652
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.34472, Val Loss: 0.34942
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.50059, Val Loss: 0.34404
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.20860, Val Loss: 0.36014
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.17243, Val Loss: 0.34459
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.52475, Val Loss: 0.34192
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.38738, Val Loss: 0.34167
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.51909, Val Loss: 0.34438
Test Accuracy: 0.8665
