_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 28.19154, Val Loss: 21.37872
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 1.56519, Val Loss: 1.36584
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.19752, Val Loss: 0.97569
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.91404, Val Loss: 0.82680
Epoch  2/10, Iteration  625/3375 --> Train Loss: 1.23617, Val Loss: 0.73994
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.09547, Val Loss: 0.68545
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 1.04691, Val Loss: 0.64490
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.70602, Val Loss: 0.62293
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.18866, Val Loss: 0.59737
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.25123, Val Loss: 0.57429
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.57947, Val Loss: 0.55323
Epoch  4/10, Iteration  875/3375 --> Train Loss: 1.12103, Val Loss: 0.54768
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.35701, Val Loss: 0.52861
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.46671, Val Loss: 0.52520
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.66427, Val Loss: 0.50220
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.45014, Val Loss: 0.49520
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.48742, Val Loss: 0.49242
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.62728, Val Loss: 0.48193
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.50070, Val Loss: 0.48169
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.13340, Val Loss: 0.47470
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.17373, Val Loss: 0.46430
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.27511, Val Loss: 0.45659
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.55985, Val Loss: 0.45862
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.62339, Val Loss: 0.45634
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.09770, Val Loss: 0.44262
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.31444, Val Loss: 0.45619
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.29522, Val Loss: 0.43741
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.73752, Val Loss: 0.43501
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.41696, Val Loss: 0.43018
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.33389, Val Loss: 0.42067
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.45826, Val Loss: 0.41749
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.10584, Val Loss: 0.43706
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.67575, Val Loss: 0.41354
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.04853, Val Loss: 0.41445
Test Accuracy: 0.8482
