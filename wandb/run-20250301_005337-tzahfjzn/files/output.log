_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running RMSpropOptimizer self.learning_rate = 0.0001 self.decay_rate = 0.9 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 4.67027, Val Loss: 7.09298
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.98574, Val Loss: 1.16223
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.47928, Val Loss: 0.88287
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.49994, Val Loss: 0.77552
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.59998, Val Loss: 0.71100
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.51964, Val Loss: 0.66679
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.43176, Val Loss: 0.63987
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.66235, Val Loss: 0.61803
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.89441, Val Loss: 0.59298
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.76866, Val Loss: 0.58264
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.34251, Val Loss: 0.56834
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.55398, Val Loss: 0.55643
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.24826, Val Loss: 0.54070
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.79843, Val Loss: 0.53041
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.10540, Val Loss: 0.53449
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 1.05533, Val Loss: 0.51652
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.32160, Val Loss: 0.51503
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.27387, Val Loss: 0.50195
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.41092, Val Loss: 0.50133
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.16450, Val Loss: 0.48932
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.37531, Val Loss: 0.49294
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.15789, Val Loss: 0.48441
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.51249, Val Loss: 0.48325
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.18810, Val Loss: 0.47843
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.78879, Val Loss: 0.47298
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.45044, Val Loss: 0.47676
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.61431, Val Loss: 0.46914
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.74788, Val Loss: 0.46579
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.59176, Val Loss: 0.46403
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.56031, Val Loss: 0.46434
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.50795, Val Loss: 0.46135
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.44194, Val Loss: 0.46141
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.29520, Val Loss: 0.45732
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.36556, Val Loss: 0.45465
Test Accuracy: 0.8345
