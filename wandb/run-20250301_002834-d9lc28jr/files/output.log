_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running MomentumOptimizer self.learning_rate = 0.001 self.momentum = 0.9
Epoch 1/5, Iteration    0/1688 --> Train Loss: 2.52622, Val Loss: 2.52799
Epoch 1/5, Iteration 1000/1688 --> Train Loss: 2.29246, Val Loss: 2.30348
Epoch 2/5, Iteration  312/1688 --> Train Loss: 2.31847, Val Loss: 2.30236
Epoch 2/5, Iteration 1312/1688 --> Train Loss: 2.29685, Val Loss: 2.30079
Epoch 3/5, Iteration  624/1688 --> Train Loss: 2.30684, Val Loss: 2.30114
Epoch 3/5, Iteration 1624/1688 --> Train Loss: 2.30754, Val Loss: 2.30027
Epoch 4/5, Iteration  936/1688 --> Train Loss: 2.30563, Val Loss: 2.29893
Epoch 5/5, Iteration  248/1688 --> Train Loss: 2.29408, Val Loss: 2.29762
Epoch 5/5, Iteration 1248/1688 --> Train Loss: 2.28704, Val Loss: 2.29433
Test Accuracy: 0.1000
