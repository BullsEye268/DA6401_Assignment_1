_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NesterovOptimizer self.learning_rate = 0.0001 self.momentum = 0.9
Epoch 1/5, Iteration    0/1688 --> Train Loss: 2.32361, Val Loss: 2.34208
Epoch 1/5, Iteration 1000/1688 --> Train Loss: 2.13841, Val Loss: 2.14102
Epoch 2/5, Iteration  312/1688 --> Train Loss: 2.26070, Val Loss: 2.25724
Epoch 2/5, Iteration 1312/1688 --> Train Loss: 2.29612, Val Loss: 2.29614
Epoch 3/5, Iteration  624/1688 --> Train Loss: 2.30156, Val Loss: 2.30197
Epoch 3/5, Iteration 1624/1688 --> Train Loss: 2.30370, Val Loss: 2.30255
Epoch 4/5, Iteration  936/1688 --> Train Loss: 2.30198, Val Loss: 2.30260
Epoch 5/5, Iteration  248/1688 --> Train Loss: 2.30285, Val Loss: 2.30260
Epoch 5/5, Iteration 1248/1688 --> Train Loss: 2.30305, Val Loss: 2.30260
Test Accuracy: 0.1000
