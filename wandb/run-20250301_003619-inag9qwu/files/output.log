_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 2.29874, Val Loss: 2.29186
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.47336, Val Loss: 0.63525
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.72329, Val Loss: 0.53106
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.54939, Val Loss: 0.48798
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.18823, Val Loss: 0.46398
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.67000, Val Loss: 0.43774
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.61795, Val Loss: 0.42950
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.55631, Val Loss: 0.42526
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.82388, Val Loss: 0.41911
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.13188, Val Loss: 0.42154
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.22785, Val Loss: 0.41162
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.39784, Val Loss: 0.40340
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.17424, Val Loss: 0.38929
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.68454, Val Loss: 0.39864
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.49269, Val Loss: 0.37111
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.29532, Val Loss: 0.37732
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.19806, Val Loss: 0.36967
Epoch  6/10, Iteration  125/3375 --> Train Loss: 1.55064, Val Loss: 0.37396
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.29140, Val Loss: 0.36861
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.30119, Val Loss: 0.36670
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.48290, Val Loss: 0.35388
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.17938, Val Loss: 0.36351
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.50270, Val Loss: 0.34792
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.21832, Val Loss: 0.35220
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.20445, Val Loss: 0.36621
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.33757, Val Loss: 0.34705
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.20775, Val Loss: 0.35573
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.51674, Val Loss: 0.37051
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.26178, Val Loss: 0.34501
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.29285, Val Loss: 0.35223
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.21644, Val Loss: 0.36668
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.17018, Val Loss: 0.33547
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.63314, Val Loss: 0.35884
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.33843, Val Loss: 0.33595
Test Accuracy: 0.8651
