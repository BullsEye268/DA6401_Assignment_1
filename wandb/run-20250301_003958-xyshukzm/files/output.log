_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 24.48246, Val Loss: 22.04144
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.88270, Val Loss: 1.18227
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 1.33272, Val Loss: 0.67738
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.39999, Val Loss: 0.58651
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.70001, Val Loss: 0.54703
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.68141, Val Loss: 0.55798
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.60507, Val Loss: 0.46414
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.64168, Val Loss: 0.45192
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.23112, Val Loss: 0.43020
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.25495, Val Loss: 0.45602
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.59806, Val Loss: 0.39077
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.14670, Val Loss: 0.40352
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.21250, Val Loss: 0.40620
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.23348, Val Loss: 0.42189
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.21688, Val Loss: 0.36169
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.40998, Val Loss: 0.38577
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.53294, Val Loss: 0.36900
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.30421, Val Loss: 0.38921
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.87569, Val Loss: 0.36112
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 1.04830, Val Loss: 0.37025
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.35371, Val Loss: 0.36808
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.34420, Val Loss: 0.38067
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.12231, Val Loss: 0.34043
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.33052, Val Loss: 0.37112
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.30608, Val Loss: 0.34137
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.16114, Val Loss: 0.36336
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.68063, Val Loss: 0.33000
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.12013, Val Loss: 0.34188
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.04169, Val Loss: 0.35834
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.29271, Val Loss: 0.36115
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.10452, Val Loss: 0.35323
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.50217, Val Loss: 0.35539
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.09814, Val Loss: 0.34656
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.05286, Val Loss: 0.37874
Test Accuracy: 0.8701
