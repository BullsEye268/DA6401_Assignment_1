_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 2.27505, Val Loss: 2.34572
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.81715, Val Loss: 0.82008
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.33018, Val Loss: 0.67089
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.47446, Val Loss: 0.61117
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.37973, Val Loss: 0.55927
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.29399, Val Loss: 0.52981
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.23387, Val Loss: 0.50845
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.92035, Val Loss: 0.49372
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.33680, Val Loss: 0.47481
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.31120, Val Loss: 0.47551
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.12206, Val Loss: 0.46521
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.39102, Val Loss: 0.44157
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.13541, Val Loss: 0.43929
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.44388, Val Loss: 0.43259
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.28624, Val Loss: 0.43434
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.50695, Val Loss: 0.41897
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.34305, Val Loss: 0.41993
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.52921, Val Loss: 0.41970
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.46777, Val Loss: 0.42879
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.40507, Val Loss: 0.40385
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.22904, Val Loss: 0.40902
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.64002, Val Loss: 0.41370
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.38149, Val Loss: 0.39266
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.36976, Val Loss: 0.39108
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.86881, Val Loss: 0.39502
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.27704, Val Loss: 0.39344
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.20541, Val Loss: 0.39274
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.41024, Val Loss: 0.38663
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.69299, Val Loss: 0.38382
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.48447, Val Loss: 0.39087
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.49246, Val Loss: 0.37878
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.25134, Val Loss: 0.37935
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.37172, Val Loss: 0.38135
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.24772, Val Loss: 0.37500
Test Accuracy: 0.8568
