_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running AdamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 28.92910, Val Loss: 26.59971
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 3.23475, Val Loss: 2.25208
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 1.48445, Val Loss: 1.56248
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 1.08398, Val Loss: 1.23937
Epoch  2/10, Iteration  625/3375 --> Train Loss: 1.51441, Val Loss: 1.07803
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.49929, Val Loss: 0.94651
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.96800, Val Loss: 0.87282
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.87462, Val Loss: 0.81692
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.64378, Val Loss: 0.76062
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 1.13997, Val Loss: 0.72419
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.57569, Val Loss: 0.71055
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.45644, Val Loss: 0.67987
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.89692, Val Loss: 0.65702
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.16416, Val Loss: 0.65887
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.46976, Val Loss: 0.62388
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.64541, Val Loss: 0.63482
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.31308, Val Loss: 0.61226
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.36250, Val Loss: 0.58507
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.28214, Val Loss: 0.58672
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.50147, Val Loss: 0.56530
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.56719, Val Loss: 0.57612
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.66907, Val Loss: 0.56219
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.54355, Val Loss: 0.56795
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.46050, Val Loss: 0.54016
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.44801, Val Loss: 0.52926
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.58153, Val Loss: 0.53064
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.43020, Val Loss: 0.52061
Epoch  9/10, Iteration    0/3375 --> Train Loss: 1.06812, Val Loss: 0.51970
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.61916, Val Loss: 0.52162
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.77778, Val Loss: 0.51064
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.29411, Val Loss: 0.50591
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.53000, Val Loss: 0.51531
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.32130, Val Loss: 0.49973
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.30310, Val Loss: 0.49727
Test Accuracy: 0.8200
