_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 25.89927, Val Loss: 28.06621
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 2.22308, Val Loss: 2.06003
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 1.35082, Val Loss: 1.36847
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 1.22734, Val Loss: 1.10302
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.94999, Val Loss: 0.93218
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 1.31303, Val Loss: 0.84141
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.86762, Val Loss: 0.77743
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.76920, Val Loss: 0.71816
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.61026, Val Loss: 0.67613
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.44191, Val Loss: 0.64123
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.33568, Val Loss: 0.60907
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.99170, Val Loss: 0.59961
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.61795, Val Loss: 0.57952
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.11001, Val Loss: 0.56649
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.55565, Val Loss: 0.54794
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.51993, Val Loss: 0.52831
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.40551, Val Loss: 0.51979
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.78012, Val Loss: 0.51055
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.38081, Val Loss: 0.50363
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.36901, Val Loss: 0.49703
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.49392, Val Loss: 0.47892
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.27475, Val Loss: 0.48085
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.29858, Val Loss: 0.46912
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.28714, Val Loss: 0.46431
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.23858, Val Loss: 0.46432
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.34435, Val Loss: 0.44792
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.18030, Val Loss: 0.44667
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.43110, Val Loss: 0.44312
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.18501, Val Loss: 0.43589
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.43793, Val Loss: 0.43730
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.13728, Val Loss: 0.43471
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.55969, Val Loss: 0.42979
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.64030, Val Loss: 0.42399
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.11606, Val Loss: 0.41680
Test Accuracy: 0.8407
