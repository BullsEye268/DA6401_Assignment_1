_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running RMSpropOptimizer self.learning_rate = 0.0001 self.decay_rate = 0.9 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 2.33046, Val Loss: 2.28687
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.80667, Val Loss: 0.75681
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.49797, Val Loss: 0.59464
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.47232, Val Loss: 0.56274
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.58663, Val Loss: 0.50081
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.68310, Val Loss: 0.48277
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.28266, Val Loss: 0.46284
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.21980, Val Loss: 0.46359
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.62880, Val Loss: 0.44459
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.46727, Val Loss: 0.43899
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.27577, Val Loss: 0.41484
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.31781, Val Loss: 0.45477
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 1.21737, Val Loss: 0.40529
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.49129, Val Loss: 0.40118
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.77433, Val Loss: 0.38988
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.20911, Val Loss: 0.38796
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.49177, Val Loss: 0.37463
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.26883, Val Loss: 0.37268
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.56784, Val Loss: 0.38844
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.21324, Val Loss: 0.38517
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.08408, Val Loss: 0.36808
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.37791, Val Loss: 0.36540
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.23275, Val Loss: 0.36466
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.05028, Val Loss: 0.37385
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.31092, Val Loss: 0.36750
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.19764, Val Loss: 0.35730
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.23831, Val Loss: 0.35455
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.28025, Val Loss: 0.35652
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.28201, Val Loss: 0.34572
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.31999, Val Loss: 0.35301
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.33255, Val Loss: 0.35274
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.25509, Val Loss: 0.35015
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.27322, Val Loss: 0.34573
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.17237, Val Loss: 0.36269
Test Accuracy: 0.8711
