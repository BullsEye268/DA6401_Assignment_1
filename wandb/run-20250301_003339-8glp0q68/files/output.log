_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running AdamOptimizer self.learning_rate = 0.001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 24.95325, Val Loss: 27.92854
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.69113, Val Loss: 1.05811
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.19756, Val Loss: 0.67093
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.44555, Val Loss: 0.59211
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.95907, Val Loss: 0.61914
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.70543, Val Loss: 0.49842
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.46018, Val Loss: 0.51408
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.58527, Val Loss: 0.45371
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.40862, Val Loss: 0.46695
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.53114, Val Loss: 0.42474
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.38313, Val Loss: 0.45697
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.40239, Val Loss: 0.39721
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.13842, Val Loss: 0.40904
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.19792, Val Loss: 0.40564
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.16711, Val Loss: 0.39268
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.17314, Val Loss: 0.37636
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.30183, Val Loss: 0.37727
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.33046, Val Loss: 0.35077
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.26918, Val Loss: 0.37809
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.72005, Val Loss: 0.40244
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.14010, Val Loss: 0.39130
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.41623, Val Loss: 0.37010
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.56193, Val Loss: 0.36125
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.84006, Val Loss: 0.36401
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.26683, Val Loss: 0.35556
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.59700, Val Loss: 0.35763
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.26064, Val Loss: 0.36692
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.39474, Val Loss: 0.34873
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.30595, Val Loss: 0.36326
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.16439, Val Loss: 0.35655
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.06087, Val Loss: 0.33809
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.10521, Val Loss: 0.35205
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.10080, Val Loss: 0.37054
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.61203, Val Loss: 0.34397
Test Accuracy: 0.8656
