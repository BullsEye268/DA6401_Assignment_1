_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 2.27746, Val Loss: 2.32155
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 0.86282, Val Loss: 0.69227
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 1.02963, Val Loss: 0.57529
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.30663, Val Loss: 0.50900
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.51337, Val Loss: 0.50090
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.47019, Val Loss: 0.48436
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.39619, Val Loss: 0.45147
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.47861, Val Loss: 0.44639
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.36974, Val Loss: 0.41899
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.63241, Val Loss: 0.42499
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.44008, Val Loss: 0.40853
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.36247, Val Loss: 0.40459
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.54399, Val Loss: 0.39288
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.61352, Val Loss: 0.38985
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.39322, Val Loss: 0.40647
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.22265, Val Loss: 0.38416
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.31697, Val Loss: 0.37540
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.92487, Val Loss: 0.37050
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 0.17758, Val Loss: 0.37597
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.54820, Val Loss: 0.36547
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.72257, Val Loss: 0.36924
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.32593, Val Loss: 0.36155
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.44258, Val Loss: 0.35885
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.23377, Val Loss: 0.36469
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.34494, Val Loss: 0.35644
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.76565, Val Loss: 0.35893
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.24366, Val Loss: 0.35365
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.21580, Val Loss: 0.34447
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.19891, Val Loss: 0.35220
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.75784, Val Loss: 0.35104
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.31969, Val Loss: 0.35328
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.21750, Val Loss: 0.34649
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.30178, Val Loss: 0.34633
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.28322, Val Loss: 0.34085
Test Accuracy: 0.8625
