_wandb
activation
batch_size
epochs
hidden_layers
hidden_size
learning_rate
optimizer
weight_decay
weight_init
Running NadamOptimizer self.learning_rate = 0.0001 self.beta1 = 0.9 self.beta2 = 0.999 self.epsilon = 1e-08
Epoch  1/10, Iteration    0/3375 --> Train Loss: 6.10877, Val Loss: 9.46906
Epoch  1/10, Iteration 1000/3375 --> Train Loss: 1.57109, Val Loss: 1.29882
Epoch  1/10, Iteration 2000/3375 --> Train Loss: 0.73502, Val Loss: 0.92637
Epoch  1/10, Iteration 3000/3375 --> Train Loss: 0.72323, Val Loss: 0.80416
Epoch  2/10, Iteration  625/3375 --> Train Loss: 0.44239, Val Loss: 0.73778
Epoch  2/10, Iteration 1625/3375 --> Train Loss: 0.43790, Val Loss: 0.68697
Epoch  2/10, Iteration 2625/3375 --> Train Loss: 0.83745, Val Loss: 0.65268
Epoch  3/10, Iteration  250/3375 --> Train Loss: 0.55010, Val Loss: 0.62795
Epoch  3/10, Iteration 1250/3375 --> Train Loss: 0.90069, Val Loss: 0.60166
Epoch  3/10, Iteration 2250/3375 --> Train Loss: 0.69424, Val Loss: 0.58688
Epoch  3/10, Iteration 3250/3375 --> Train Loss: 0.51294, Val Loss: 0.57614
Epoch  4/10, Iteration  875/3375 --> Train Loss: 0.54528, Val Loss: 0.56052
Epoch  4/10, Iteration 1875/3375 --> Train Loss: 0.65424, Val Loss: 0.54796
Epoch  4/10, Iteration 2875/3375 --> Train Loss: 0.34372, Val Loss: 0.53432
Epoch  5/10, Iteration  500/3375 --> Train Loss: 0.40640, Val Loss: 0.52803
Epoch  5/10, Iteration 1500/3375 --> Train Loss: 0.35702, Val Loss: 0.52131
Epoch  5/10, Iteration 2500/3375 --> Train Loss: 0.32524, Val Loss: 0.51200
Epoch  6/10, Iteration  125/3375 --> Train Loss: 0.34005, Val Loss: 0.50158
Epoch  6/10, Iteration 1125/3375 --> Train Loss: 1.04815, Val Loss: 0.49831
Epoch  6/10, Iteration 2125/3375 --> Train Loss: 0.28339, Val Loss: 0.49128
Epoch  6/10, Iteration 3125/3375 --> Train Loss: 0.64323, Val Loss: 0.48335
Epoch  7/10, Iteration  750/3375 --> Train Loss: 0.25929, Val Loss: 0.48337
Epoch  7/10, Iteration 1750/3375 --> Train Loss: 0.51473, Val Loss: 0.47400
Epoch  7/10, Iteration 2750/3375 --> Train Loss: 0.38374, Val Loss: 0.46600
Epoch  8/10, Iteration  375/3375 --> Train Loss: 0.76488, Val Loss: 0.46461
Epoch  8/10, Iteration 1375/3375 --> Train Loss: 0.27862, Val Loss: 0.46002
Epoch  8/10, Iteration 2375/3375 --> Train Loss: 0.74512, Val Loss: 0.45406
Epoch  9/10, Iteration    0/3375 --> Train Loss: 0.28120, Val Loss: 0.45212
Epoch  9/10, Iteration 1000/3375 --> Train Loss: 0.33005, Val Loss: 0.44919
Epoch  9/10, Iteration 2000/3375 --> Train Loss: 0.55384, Val Loss: 0.44389
Epoch  9/10, Iteration 3000/3375 --> Train Loss: 0.62677, Val Loss: 0.44611
Epoch 10/10, Iteration  625/3375 --> Train Loss: 0.22999, Val Loss: 0.43669
Epoch 10/10, Iteration 1625/3375 --> Train Loss: 0.72898, Val Loss: 0.43528
Epoch 10/10, Iteration 2625/3375 --> Train Loss: 0.30898, Val Loss: 0.43164
Test Accuracy: 0.8385
